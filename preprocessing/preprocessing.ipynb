{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "071142a0",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "In this notebook, I hope to create a class that will scale the data both with standardized scaling (subtracting the mean and dividing the difference by the standard deviation) and the max min scaling (subtracting the min and dividing the difference by the range of the max and min of the dataset).\n",
    "\n",
    "In addition to the scaling, I will also include a train_test split as part of the class as well, to ensure that the data is ready to go for the models in the next notebook.\n",
    "\n",
    "Finally, the class will produce two sets of data representing variable lengths of fictitiuos proteins with random amino acid sequences (barring the required start with the methionine residue)\n",
    "\n",
    "This project is dedicated towards seeing if there is a clear way to indicate a high probabilites if proteins will interaction with each other based on the qualities of the respective proteins.  The proteins were analyzed according to their sequence; from thsoe sequences, several features were engineerd: chiefly quantitave counts of different kinds of features contained by the different amino acids.  These features include the amount of hydrophobic amino acid residues, hydrophilic residues, basic residues. etc.\n",
    "\n",
    "With the development of these features, the data will be fed into a classification model, wherein the model will predict whether or not protein 1 and protein 2 will interact with each other.\n",
    "\n",
    "Inputs: the features of the proteins\n",
    "\n",
    "Outputs: a 0 if the proteins do not interact or a 1 if the proteins do interact\n",
    "\n",
    "The data was originally a set of two csv files; one for interacting proteins and one for non interacting proteins.  The individual csvs contained two protein sequences each.\n",
    "\n",
    "The data is coming from kaggle https://www.kaggle.com/datasets/spandansureja/ppi-dataset?resource=download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac674d81",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbb4d13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "34f6a95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class preprocessing:\n",
    "    \n",
    "    def __init__(self, df_path):\n",
    "        self.df = pd.read_csv(df_path)\n",
    "        self.df = self.df.drop(columns='Unnamed: 0')\n",
    "        \n",
    "        \n",
    "    def show(self):\n",
    "        return self.df\n",
    "    \n",
    "    def basic(self):\n",
    "        \n",
    "        df = self.df\n",
    "        features = list(df.columns[df.columns != 'protein_interaction'])\n",
    "        \n",
    "        X = df[features]\n",
    "        \n",
    "        y = df['protein_interaction']\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3, random_state = 7, stratify=y)\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "        \n",
    "    \n",
    "    def standard(self):\n",
    "        \n",
    "        df = self.df\n",
    "        \n",
    "        features = list(df.columns[df.columns != 'protein_interaction'])\n",
    "        \n",
    "        features.remove('protein_1_seq')\n",
    "        \n",
    "        features.remove('protein_2_seq')\n",
    "        \n",
    "        X = df[features]\n",
    "        \n",
    "        y = df['protein_interaction']\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3, random_state = 7, stratify=y)\n",
    "        \n",
    "        stan_scal = StandardScaler()\n",
    "        \n",
    "        X_train = stan_scal.fit_transform(X_train)\n",
    "        \n",
    "        X_test = stan_scal.transform(X_test)\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    \n",
    "    def minmax(self):\n",
    "        \n",
    "        df = self.df\n",
    "        \n",
    "        features = list(df.columns[df.columns != 'protein_interaction'])\n",
    "        \n",
    "        features.remove('protein_1_seq')\n",
    "        \n",
    "        features.remove('protein_2_seq')\n",
    "        \n",
    "        X = df[features]\n",
    "        \n",
    "        y = df['protein_interaction']\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3, random_state = 7, stratify=y)\n",
    "        \n",
    "        mm_scal = MinMaxScaler()\n",
    "        \n",
    "        X_train = mm_scal.fit_transform(X_train)\n",
    "        \n",
    "        X_test= mm_scal.transform(X_test)\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    \n",
    "    \n",
    "    def standard_nonsense(self):\n",
    "        \n",
    "        structure = {'protein_1_len':0, '1_phobic_count':0, '1_philic_count':0, '1_basic_count': 0, '1_acidic_count': 0, '1_aromatic_count':0, '1_sulfur_count': 0, 'protein_2_len':0, '2_phobic_count':0, '2_philic_count':0, '2_basic_count': 0, '2_acidic_count': 0, '2_aromatic_count':0, '2_sulfur_count': 0}\n",
    "        \n",
    "        new_df = pd.DataFrame(data=structure, index=[0])\n",
    "        \n",
    "        amino_acids = ['A','C','D','E','F','G','H','I','K','L','M','N','P','Q','R','S','T','V','W','Y']\n",
    "        \n",
    "        rng = np.random.default_rng()\n",
    "        \n",
    "        for x in range(2500):\n",
    "        \n",
    "            size_rng_1 =rng.integers(low=24, high=33000)\n",
    "        \n",
    "            seq_rng_1 = random.choices(amino_acids, k=size_rng_1)\n",
    "            \n",
    "            size_rng_2 =rng.integers(low=24, high=33000)\n",
    "        \n",
    "            seq_rng_2 = random.choices(amino_acids, k=size_rng_2)\n",
    "            \n",
    "            seq_hold = [seq_rng_1, seq_rng_2]\n",
    "        \n",
    "            p1_list = []\n",
    "            p2_list = []\n",
    "\n",
    "            for i in range(2):\n",
    "\n",
    "                phobic = {'A':0, 'F':0, 'G':0, 'I':0, 'L':0, 'M':0, 'P':0, 'V':0, 'W':0, 'Y':0, 'phobic_total':0}\n",
    "                philic = {'C':0, 'D':0, 'E':0, 'H':0, 'K':0, 'N':0, 'Q':0, 'R':0, 'S':0, 'T':0, 'philic_total':0}\n",
    "                basic = {'H':0, 'K':0, 'R':0, 'basic_total':0}\n",
    "                acidic = {'D':0, 'E':0, 'acidic_total':0}\n",
    "                aromatic = {'F':0, 'H':0, 'W':0, 'Y':0, 'aromatic_total':0}\n",
    "                sulfur = {'C':0 , 'M':0, 'sulfur_total':0}\n",
    "\n",
    "                seq = seq_hold[i]\n",
    "                    \n",
    "                seq_len = len(seq)\n",
    "\n",
    "                for z in seq:\n",
    "                    \n",
    "                    if z in phobic:\n",
    "                        phobic[z] += 1\n",
    "                        phobic['phobic_total'] += 1\n",
    "\n",
    "                    if z in philic:\n",
    "                        philic[z] += 1\n",
    "                        philic['philic_total'] += 1\n",
    "\n",
    "                    if z in basic:\n",
    "                        basic[z] += 1\n",
    "                        basic['basic_total'] += 1\n",
    "\n",
    "                    if z in acidic:\n",
    "                        acidic[z] += 1\n",
    "                        acidic['acidic_total'] += 1\n",
    "\n",
    "                    if z in aromatic:\n",
    "                        aromatic[z] += 1\n",
    "                        aromatic['aromatic_total'] += 1\n",
    "\n",
    "                    if z in sulfur:\n",
    "                        sulfur[z] += 1\n",
    "                        sulfur['sulfur_total'] += 1\n",
    "\n",
    "\n",
    "                if i == 0:\n",
    "\n",
    "                    p1_list = [seq_len, phobic['phobic_total'], philic['philic_total'], basic['basic_total'], acidic['acidic_total'], aromatic['aromatic_total'], sulfur['sulfur_total']]\n",
    "\n",
    "                elif i != 0:\n",
    "\n",
    "                    p2_list = [seq_len, phobic['phobic_total'], philic['philic_total'], basic['basic_total'], acidic['acidic_total'], aromatic['aromatic_total'], sulfur['sulfur_total']]\n",
    "\n",
    "            tot_list = p1_list + p2_list\n",
    "            col_list = [k for k,v in structure.items()]\n",
    "\n",
    "            moving_dict = dict(zip(col_list, tot_list))\n",
    "\n",
    "            moving_df = pd.DataFrame(data = moving_dict, index= [0])\n",
    "\n",
    "            new_df = pd.concat([new_df, moving_df], axis = 0)\n",
    "            \n",
    "        new_df = new_df.reset_index(drop=True)\n",
    "        \n",
    "        new_df = new_df.drop(index=[0])\n",
    "        \n",
    "        zeros_ones = (rng.integers(low=0, high=2, size=2500)).tolist()\n",
    "            \n",
    "        new_df['protein_interaction'] = zeros_ones\n",
    "        \n",
    "        #return new_df\n",
    "        \n",
    "        features = list(new_df.columns[new_df.columns != 'protein_interaction'])\n",
    "            \n",
    "        X = new_df[features]\n",
    "        \n",
    "        y = new_df['protein_interaction']\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3, random_state = 7, stratify=y)\n",
    "        \n",
    "        stan_scal = StandardScaler()\n",
    "        \n",
    "        X_train = stan_scal.fit_transform(X_train)\n",
    "        \n",
    "        X_test = stan_scal.transform(X_test)\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    \n",
    "    \n",
    "    def minmax_nonsense(self):\n",
    "        \n",
    "        structure = {'protein_1_len':0, '1_phobic_count':0, '1_philic_count':0, '1_basic_count': 0, '1_acidic_count': 0, '1_aromatic_count':0, '1_sulfur_count': 0, 'protein_2_len':0, '2_phobic_count':0, '2_philic_count':0, '2_basic_count': 0, '2_acidic_count': 0, '2_aromatic_count':0, '2_sulfur_count': 0}\n",
    "        \n",
    "        new_df = pd.DataFrame(data=structure, index=[0])\n",
    "        \n",
    "        amino_acids = ['A','C','D','E','F','G','H','I','K','L','M','N','P','Q','R','S','T','V','W','Y']\n",
    "        \n",
    "        rng = np.random.default_rng()\n",
    "        \n",
    "        for x in range(2500):\n",
    "        \n",
    "            size_rng_1 =rng.integers(low=24, high=33000)\n",
    "        \n",
    "            seq_rng_1 = random.choices(amino_acids, k=size_rng_1)\n",
    "            \n",
    "            size_rng_2 =rng.integers(low=24, high=33000)\n",
    "        \n",
    "            seq_rng_2 = random.choices(amino_acids, k=size_rng_2)\n",
    "            \n",
    "            seq_hold = [seq_rng_1, seq_rng_2]\n",
    "        \n",
    "            p1_list = []\n",
    "            p2_list = []\n",
    "\n",
    "            for i in range(2):\n",
    "\n",
    "                phobic = {'A':0, 'F':0, 'G':0, 'I':0, 'L':0, 'M':0, 'P':0, 'V':0, 'W':0, 'Y':0, 'phobic_total':0}\n",
    "                philic = {'C':0, 'D':0, 'E':0, 'H':0, 'K':0, 'N':0, 'Q':0, 'R':0, 'S':0, 'T':0, 'philic_total':0}\n",
    "                basic = {'H':0, 'K':0, 'R':0, 'basic_total':0}\n",
    "                acidic = {'D':0, 'E':0, 'acidic_total':0}\n",
    "                aromatic = {'F':0, 'H':0, 'W':0, 'Y':0, 'aromatic_total':0}\n",
    "                sulfur = {'C':0 , 'M':0, 'sulfur_total':0}\n",
    "\n",
    "                seq = seq_hold[i]\n",
    "                    \n",
    "                seq_len = len(seq)\n",
    "\n",
    "                for z in seq:\n",
    "                    \n",
    "                    if z in phobic:\n",
    "                        phobic[z] += 1\n",
    "                        phobic['phobic_total'] += 1\n",
    "\n",
    "                    if z in philic:\n",
    "                        philic[z] += 1\n",
    "                        philic['philic_total'] += 1\n",
    "\n",
    "                    if z in basic:\n",
    "                        basic[z] += 1\n",
    "                        basic['basic_total'] += 1\n",
    "\n",
    "                    if z in acidic:\n",
    "                        acidic[z] += 1\n",
    "                        acidic['acidic_total'] += 1\n",
    "\n",
    "                    if z in aromatic:\n",
    "                        aromatic[z] += 1\n",
    "                        aromatic['aromatic_total'] += 1\n",
    "\n",
    "                    if z in sulfur:\n",
    "                        sulfur[z] += 1\n",
    "                        sulfur['sulfur_total'] += 1\n",
    "\n",
    "\n",
    "                if i == 0:\n",
    "\n",
    "                    p1_list = [seq_len, phobic['phobic_total'], philic['philic_total'], basic['basic_total'], acidic['acidic_total'], aromatic['aromatic_total'], sulfur['sulfur_total']]\n",
    "\n",
    "                elif i != 0:\n",
    "\n",
    "                    p2_list = [seq_len, phobic['phobic_total'], philic['philic_total'], basic['basic_total'], acidic['acidic_total'], aromatic['aromatic_total'], sulfur['sulfur_total']]\n",
    "\n",
    "            tot_list = p1_list + p2_list\n",
    "            col_list = [k for k,v in structure.items()]\n",
    "\n",
    "            moving_dict = dict(zip(col_list, tot_list))\n",
    "\n",
    "            moving_df = pd.DataFrame(data = moving_dict, index= [0])\n",
    "\n",
    "            new_df = pd.concat([new_df, moving_df], axis = 0)\n",
    "            \n",
    "        new_df = new_df.reset_index(drop=True)\n",
    "        \n",
    "        new_df = new_df.drop(index=[0])\n",
    "        \n",
    "        zeros_ones = (rng.integers(low=0, high=2, size=2500)).tolist()\n",
    "            \n",
    "        new_df['protein_interaction'] = zeros_ones\n",
    "        \n",
    "        #return new_df\n",
    "        \n",
    "        features = list(new_df.columns[new_df.columns != 'protein_interaction'])\n",
    "            \n",
    "        X = new_df[features]\n",
    "        \n",
    "        y = new_df['protein_interaction']\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3, random_state = 7, stratify=y)\n",
    "        \n",
    "        mm_scal = MinMaxScaler()\n",
    "        \n",
    "        X_train = mm_scal.fit_transform(X_train)\n",
    "        \n",
    "        X_test= mm_scal.transform(X_test)\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f92b1cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loaded = preprocessing('feature_engineered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "793ad183",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reveal = df_loaded.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d8f19f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reveal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "535b55ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#base = df_loaded.basic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6b505f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (base[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8c4057ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stan = df_loaded.standard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ba1188a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stan[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d4153bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#minmax = df_loaded.minmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "38be0500",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (minmax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "14d87984",
   "metadata": {},
   "outputs": [],
   "source": [
    "#minmax[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ba2b8a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stan_non = df_loaded.standard_nonsense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7ca92bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.12379772  1.1267519   1.12063889 ... -1.26430076 -1.24957043\n",
      "  -1.28293183]\n",
      " [-0.8544594  -0.85435459 -0.85440987 ... -0.97910993 -0.96978497\n",
      "  -0.98903774]\n",
      " [-0.36785339 -0.35483857 -0.38080872 ... -1.27908843 -1.31186229\n",
      "  -1.23974309]\n",
      " ...\n",
      " [ 0.57132659  0.56945448  0.57309647 ...  0.4648007   0.56481188\n",
      "   0.53942221]\n",
      " [-1.54703788 -1.54584722 -1.54794963 ...  0.77956688  0.78336128\n",
      "   0.76695312]\n",
      " [ 0.07875188  0.07684711  0.08064344 ...  1.26967261  1.22890643\n",
      "   1.25782999]]\n"
     ]
    }
   ],
   "source": [
    "print (stan_non[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "3c77f422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750, 14)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stan_non[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "108d69fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax_non = df_loaded.minmax_nonsense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2c17eb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.73627743 0.73724875 0.72957541 ... 0.0618095  0.06723827 0.05133411]\n",
      " [0.59552611 0.59171848 0.59472757 ... 0.03015826 0.02888087 0.02552204]\n",
      " [0.36541852 0.3630108  0.3650003  ... 0.64467005 0.63086643 0.63486079]\n",
      " ...\n",
      " [0.52729317 0.52507998 0.52542064 ... 0.18333831 0.18306258 0.17024362]\n",
      " [0.68491277 0.68280316 0.6817105  ... 0.76470588 0.78203971 0.74767981]\n",
      " [0.49106437 0.48795799 0.49037235 ... 0.3592117  0.34792419 0.35817865]]\n"
     ]
    }
   ],
   "source": [
    "print (minmax_non[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b22de9",
   "metadata": {},
   "source": [
    "# Summary:\n",
    "\n",
    "Now I have access to the training and test data that is split appropriately, along with standard and minmax scaling options as well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
